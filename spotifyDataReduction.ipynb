{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Data Reduction\n",
    "\n",
    "We decided to model Spotify representing Tracks, Albums, Artists, Genres and Charts.\n",
    "\n",
    "As a starting point, we downloaded a dataset from Kaggle that contains all the songs in Spotify's Daily Top 200 charts in 35+1 (global) countries around the world for a period of over 3 years (2017-2020):\n",
    "\n",
    "**https://www.kaggle.com/pepepython/spotify-huge-database-daily-charts-over-3-years?select=Database+to+calculate+popularity.csv**\n",
    "\n",
    "\n",
    "Since this initial dataset is very huge (1.53 GB), we decided to reduce the initial CSV file in order to obtain a smaller CSV file that is suitable for our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We import all the necessary libraries and we set the paths to the input/output files.\n",
    "* **input file** must be called \"spotifyCharts.csv\"\n",
    "* **output file** will be called \"reducedSpotifyCharts.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get absolute path\n",
    "absPath = str(Path(os.path.abspath(os.getcwd())).absolute())\n",
    "\n",
    "# All the datasets must be placed in a single folder called \"datasets\"\n",
    "datasetsPath = os.path.join(absPath, \"datasets\")\n",
    "\n",
    "# Create datasets directory if not exists\n",
    "if not os.path.exists(datasetsPath):\n",
    "    os.mkdir(datasetsPath)\n",
    "\n",
    "# Setup datasets paths\n",
    "spotifyChartsPath = os.path.join(datasetsPath, \"spotifyCharts.csv\")\n",
    "spotifyReducedChartsPath = os.path.join(datasetsPath, \"reducedSpotifyCharts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spotify Charts\n",
    "trackCharts = pd.read_csv(spotifyChartsPath, sep=\",\", index_col=0)\n",
    "\n",
    "# Drop NaN columns\n",
    "trackCharts = trackCharts.dropna()\n",
    "\n",
    "# Print track charts info\n",
    "trackCharts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling \n",
    "\n",
    "We define a function to reduce the dataframe using two parameters:\n",
    "* **onlyFirst** to select only the first *x* tracks of the charts. For example, using *onlyFirst = 50*, only the top 50 songs are taken.\n",
    "* **daysRange** to sample charts every *x* days. For example, using *daysRange = 7*, you will have only a chart for each week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectSamples(trackCharts, onlyFirst=-1, daysRange=7):\n",
    "    reducedTrackCharts = pd.DataFrame()\n",
    "\n",
    "    # First and final date in the csv\n",
    "    firstDateStr = trackCharts.iloc[-1][\"date\"]\n",
    "    endDateStr = trackCharts.iloc[0][\"date\"]\n",
    "\n",
    "    # Initialize for the while\n",
    "    actualDate = datetime.strptime(firstDateStr, \"%d/%m/%Y\").date()\n",
    "    endDate = datetime.strptime(endDateStr, \"%d/%m/%Y\").date()\n",
    "\n",
    "    while(actualDate < endDate):\n",
    "        if onlyFirst > 0:\n",
    "            reducedTrackCharts = pd.concat([reducedTrackCharts, trackCharts.loc[\n",
    "                (trackCharts['date'] == actualDate.strftime(\"%d/%m/%Y\")) &\n",
    "                (trackCharts['position'] <= onlyFirst)\n",
    "            ]], ignore_index=True)\n",
    "        else:\n",
    "            reducedTrackCharts = pd.concat(\n",
    "                [reducedTrackCharts, trackCharts.loc[\n",
    "                    trackCharts['date'] == actualDate.strftime(\"%d/%m/%Y\")\n",
    "                ]], ignore_index=True)\n",
    "    \n",
    "        actualDate = actualDate + timedelta(days=daysRange)\n",
    "    \n",
    "    return reducedTrackCharts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For our project we decided to retrieve a ***weekly TOP 100***, obtaining a smaller CSV file (109 MB vs 1.53 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the chart tracks\n",
    "reducedTrackCharts = selectSamples(trackCharts, onlyFirst=100, daysRange=7)\n",
    "\n",
    "# Print DataFrame info\n",
    "reducedTrackCharts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to file\n",
    "reducedTrackCharts.to_csv(spotifyReducedChartsPath)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

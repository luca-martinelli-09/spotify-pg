{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# People Data Retrieval\n",
    "\n",
    "Since the  ***Spotify Web API*** do not give personal information about the artists, we decided to retrieve more date relying on two different services:\n",
    "* ***WikiData API***: https://www.wikidata.org/w/api.php\n",
    "* ***MusicBrainz API***: https://musicbrainz.org/doc/MusicBrainz_API\n",
    "\n",
    "The second one is an open music encyclopedia that collects music metadata and makes it available to the public.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We import all the necessary libraries and we set the paths to the input/output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import urllib.parse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get absolute path\n",
    "absPath = str(Path(os.path.abspath(os.getcwd())).absolute())\n",
    "datasetsPath = os.path.join(absPath, \"datasets\")\n",
    "\n",
    "# Create dataset directory if not exists\n",
    "if not os.path.exists(datasetsPath):\n",
    "    os.mkdir(datasetsPath)\n",
    "\n",
    "# Setup datasets paths\n",
    "artistsPath = os.path.join(datasetsPath, \"artists.csv\")\n",
    "peoplePath = os.path.join(datasetsPath, \"people.csv\")\n",
    "recordLabelsPath = os.path.join(datasetsPath, \"recordLabels.csv\")\n",
    "instrumentsPath = os.path.join(datasetsPath, \"instruments.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiData API Functions\n",
    "We defined the functions necessary to interact with the ***WikiData API*** according to the official documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to WikiData to get a list of search results. Ideally the first result should be the one we are looking for\n",
    "def wdQuery(query):\n",
    "    # Format the request (encoding the query text)\n",
    "    queryApiRequest = requests.get(\n",
    "        \"https://www.wikidata.org/w/api.php?action=query&format=json&list=search&srsearch={q}&srlimit=20\".format(q=urllib.parse.quote_plus(query)))\n",
    "    \n",
    "    # If there is a response, then return the json\n",
    "    if queryApiRequest.status_code == 200:\n",
    "        return json.loads(queryApiRequest.text)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Query to WikiData to get the entity information from the ID retrieved from the query results\n",
    "def wdGetEntity(entityID):\n",
    "    # Format the request\n",
    "    queryApiRequest = requests.get(\n",
    "        \"https://www.wikidata.org/w/api.php?action=wbgetentities&ids={eID}&format=json\".format(eID=entityID))\n",
    "\n",
    "    # If there is a response, then return the json\n",
    "    if queryApiRequest.status_code == 200:\n",
    "        return json.loads(queryApiRequest.text)[\"entities\"][entityID]\n",
    "\n",
    "    return None\n",
    "\n",
    "def wdGetProperty(entityID, propertyID):\n",
    "    # Format the request\n",
    "    queryApiRequest = requests.get(\n",
    "        \"https://www.wikidata.org/w/api.php?action=wbgetclaims&entity={eID}&property={pID}&format=json\".format(eID=entityID, pID=propertyID))\n",
    "\n",
    "    # If there is a valid response, then return the json\n",
    "    if queryApiRequest.status_code == 200:\n",
    "        try:\n",
    "            return json.loads(queryApiRequest.text)[\"claims\"][propertyID]\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MusicBrainz API Functions\n",
    "We defined the functions necessary to interact with the ***MusicBrainz API*** according to the official documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbQuery(query):\n",
    "    # Format the request (encoding the query text)\n",
    "    queryApiRequest = requests.get(\n",
    "        \"https://musicbrainz.org/ws/2/artist?query={q}&limit=20&fmt=json\".format(q=urllib.parse.quote_plus(query.lower().removeprefix(\"the \"))))\n",
    "\n",
    "    # If there is a response, then return the json\n",
    "    if queryApiRequest.status_code == 200:\n",
    "        return json.loads(queryApiRequest.text)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Get the artist information. From MusicBrainz API, using includes can\n",
    "# be retrieved also other information, like aliases, urls, artists relationships etc.\n",
    "# By default mbGetArtist uses aliases and url-rels. For artists (like members of group)\n",
    "# can be used artist-rels. Other type in the API documentation.\n",
    "def mbGetArtist(artistID, includes=None):\n",
    "    includesStr = \"+\" + \"+\".join(includes) if not includes is None and len(includes) > 0 else \"\"\n",
    "    # Format the request\n",
    "    queryApiRequest = requests.get(\n",
    "        \"https://musicbrainz.org/ws/2/artist/{artistID}?fmt=json&inc=aliases+url-rels{incs}\".format(artistID=artistID, incs=includesStr))\n",
    "\n",
    "    # If there is a response, then return the json\n",
    "    if queryApiRequest.status_code == 200:\n",
    "        return json.loads(queryApiRequest.text)\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Utilities\n",
    "We mapped the properties and the entities codes with a more human readable name and we set the datatypes for the data that we want to retrieve. In particular, we have:\n",
    "* ***externalArrayString*** is an array of strings that WikiData treats as external entities\n",
    "* ***externalString*** is a string that WikiData treats as external entities\n",
    "* ***inValue*** is a string contained in \"targetProperty\" field\n",
    "* ***date*** is a date contained in the datavalue field\n",
    "* ***country*** is an external property of the entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the properties and the entities codes with a human-friendly name\n",
    "WD_MAP = {\n",
    "    \"instanceOf\": \"P31\",\n",
    "    \"name\": \"P735\",\n",
    "    \"birthName\": \"P1477\",\n",
    "    \"surname\": \"P734\",\n",
    "    \"birthDate\": \"P569\",\n",
    "    \"deathDate\": \"P570\",\n",
    "    \"country\": \"P27\",\n",
    "    \"country2\": \"P17\",\n",
    "    \"countryISOCode\": \"P297\",\n",
    "    \"hasPart\": \"P527\",\n",
    "    \"human\": \"Q5\",\n",
    "    \"nativeName\": \"P1705\",\n",
    "    \"musicalGroup\": \"Q215380\",\n",
    "    \"recordLabels\": \"P264\",\n",
    "    \"gender\": \"P21\",\n",
    "    \"instruments\": \"P1303\",\n",
    "}\n",
    "\n",
    "# Set the types of the retrieved data, this will be used next to get the values from the properties\n",
    "\n",
    "WD_DATA_TYPE = {\n",
    "    \"name\": {\"type\": \"externalArrayString\"},\n",
    "    \"birthName\": {\"type\": \"inValue\", \"targetProperty\": \"text\"},\n",
    "    \"surname\": {\"type\": \"externalArrayString\"},\n",
    "    \"birthDate\": {\"type\": \"date\"},\n",
    "    \"deathDate\": {\"type\": \"date\"},\n",
    "    \"country\": {\"type\": \"externalProperty\", \"targetProperty\": WD_MAP[\"countryISOCode\"]},\n",
    "    \"country2\": {\"type\": \"externalProperty\", \"targetProperty\": WD_MAP[\"countryISOCode\"]},\n",
    "    \"recordLabels\": {\"type\": \"inValueArray\", \"targetProperty\": \"id\"},\n",
    "    \"gender\": {\"type\": \"externalString\"},\n",
    "    \"instruments\": {\"type\": \"externalArrayString\"},\n",
    "}\n",
    "\n",
    "# The properties to be retrieved for persons or groups\n",
    "HUMAN_KEYS = [\"name\", \"surname\", \"birthName\", \"birthDate\",\n",
    "              \"deathDate\", \"country\", \"gender\", \"recordLabels\", \"instruments\"]\n",
    "GROUP_KEYS = [\"hasPart\", \"recordLabels\"]\n",
    "RECORDLABEL_KEYS = [\"country2\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Utilities\n",
    "We define some functions that will be useful in different contexts (like managing dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a subset of properties from a WikiData entity\n",
    "def getSubsetOfKeys(dictObject, keys):\n",
    "    resultObject = {}\n",
    "\n",
    "    for key in keys:\n",
    "        # If there is the property, then add it, otherwise add a null value\n",
    "        # The new dictionary will have instead of WikiData key property, the one in the WD_MAP\n",
    "        if WD_MAP[key] in dictObject.keys():\n",
    "            resultObject[key] = dictObject[WD_MAP[key]]\n",
    "        else:\n",
    "            resultObject[key] = None\n",
    "\n",
    "    return resultObject\n",
    "\n",
    "# Convert WikiData date into a datetime formatted as Y-m-d\n",
    "def getDateFromInformation(dateTime, datePrecision):\n",
    "    # WikiData put 00 in the field month or day for not precise dates\n",
    "    # This will raise an exception because is a malformed datetime\n",
    "    dateFormats = [\"+%Y-%m-%dT%H:%M:%SZ\", \"+%Y-%m-00T%H:%M:%SZ\", \"+%Y-00-00T00:00:00Z\"]\n",
    "    destinationFormats = {\"year\": \"%Y\", \"month\": \"%Y-%m\", \"day\": \"%Y-%m-%d\"}\n",
    "\n",
    "    destinationFormat = destinationFormats[\"day\"]\n",
    "    if datePrecision == 10:\n",
    "        destinationFormat = destinationFormats[\"month\"]\n",
    "    elif datePrecision <= 9:\n",
    "        destinationFormat = destinationFormats[\"year\"]\n",
    "\n",
    "    for dateFormat in dateFormats:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(\n",
    "                dateTime, dateFormat\n",
    "            ).strftime(destinationFormat)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WikiData Entity Utilites\n",
    "WikiData is structured as: \n",
    "\n",
    "***claims --> property --> {0,1,...} --> mainsnak --> datavalue --> value***\n",
    "\n",
    "So, we define a function to return an array of values (or a single value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return an array of only values (or a single value)\n",
    "def getDataValue(dictObject, keyProperty=None, expectArray=False):\n",
    "    arrValues = []\n",
    "    \n",
    "    # Check if the property exists in the WikiData entity\n",
    "    dictPropObject = dictObject if keyProperty is None else dictObject[keyProperty]\n",
    "\n",
    "    if dictPropObject is None:\n",
    "        return None\n",
    "\n",
    "    for keyValue in dictPropObject:\n",
    "        # If there is a property with no value, datavalue is not present\n",
    "        if \"datavalue\" in keyValue[\"mainsnak\"].keys():\n",
    "            valueToAppend = keyValue[\"mainsnak\"][\"datavalue\"][\"value\"]\n",
    "            arrValues.append(valueToAppend)\n",
    "    \n",
    "    # If there are no values return a null object\n",
    "    if len(arrValues) <= 0:\n",
    "        return None\n",
    "\n",
    "    # If an array is expected return an array, otherwise return only the first value\n",
    "    return arrValues[0] if not expectArray else arrValues\n",
    "\n",
    "# Get the title of the entity\n",
    "def getEntityTitle(entity):\n",
    "    try:\n",
    "        # If there is the english version of the entity, get it\n",
    "        return entity[\"labels\"][\"en\"][\"value\"]\n",
    "    except:\n",
    "        # Otherwise select the first one version\n",
    "        return entity[\"labels\"][list(entity[\"labels\"])[0]][\"value\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MusicBrainz Utilites\n",
    "We define some functions to interact with the data retrieved from MusicBrainz.\n",
    "\n",
    "***MusicBrainz*** return a list of relations, and often there is a wikidata link that connect the artist to its ***WikiData*** page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MusicBrainz return a list of relations. Often there is a wikidata link\n",
    "# that connect the artist to its WikiData page\n",
    "def getMBWikiDataEntityID(artistInformation):\n",
    "    # If there are relations, check until it finds the wikidata one, and extract the entity ID from the link\n",
    "    try:\n",
    "        for artistRelation in artistInformation[\"relations\"]:\n",
    "            if artistRelation[\"type\"] == \"wikidata\":\n",
    "                return artistRelation[\"url\"][\"resource\"].removeprefix(\"https://www.wikidata.org/wiki/\").strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Otherwise return null\n",
    "    return None\n",
    "\n",
    "# MusicBrainz return a list of relations. If it is a group, a list of members often is retrieved\n",
    "def getMBGroupMembers(artistInformation, downloadMembers=False):\n",
    "    # If there are relations, check until it finds the wikidata one, and extract the entity ID from the link\n",
    "    groupMembers = []\n",
    "    gropuMembersIDS = []\n",
    "\n",
    "    if not artistInformation is None and downloadMembers:\n",
    "        artistInformation = mbGetArtist(artistInformation[\"id\"], includes=[\"artist-rels\"])\n",
    "\n",
    "    # If there are no relations, then return null\n",
    "    if artistInformation is None or not \"relations\" in artistInformation.keys():\n",
    "        return None\n",
    "    \n",
    "    # Check all the relations\n",
    "    for artistRelation in artistInformation[\"relations\"]:\n",
    "        try:\n",
    "            # If the relation is of type \"member of band\", try get the information of the artist\n",
    "            if artistRelation[\"type\"] == \"member of band\" and artistRelation[\"direction\"] == \"backward\":\n",
    "                if not artistRelation[\"artist\"][\"id\"] in gropuMembersIDS:\n",
    "                    getMemberInformation = mbGetArtist(artistRelation[\"artist\"][\"id\"])\n",
    "                    groupMembers.append(getMemberInformation)\n",
    "                    gropuMembersIDS.append(artistRelation[\"artist\"][\"id\"])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Otherwise return null\n",
    "    return groupMembers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artist Retrieved Data Utilities\n",
    "We define some functions to get data both from ***Wikidata*** and ***MusicBrainz***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from a \"human\" WikiData entity\n",
    "def getEntityInformation(entityClaims, keysToGet=HUMAN_KEYS):\n",
    "    # Get only the intersted properties\n",
    "    artistInformation = getSubsetOfKeys(entityClaims, keysToGet)\n",
    "    artistExtractedInformation = {}\n",
    "\n",
    "    # For each property, check the type in WD_DATA_TYPE and act differently\n",
    "    for keyValue in artistInformation:\n",
    "        # Get the data value, as an object or as an array, depending on the data type\n",
    "        expectArray = WD_DATA_TYPE[keyValue][\"type\"] == \"externalArrayString\" or WD_DATA_TYPE[keyValue][\"type\"] == \"inValueArray\"\n",
    "        currentInformation = getDataValue(artistInformation, keyValue, expectArray=expectArray)\n",
    "\n",
    "        realValue = None\n",
    "        if not currentInformation is None:\n",
    "            # Get information about the datatype\n",
    "            wdDataInformation = WD_DATA_TYPE[keyValue]\n",
    "\n",
    "            # The data is the name of an external entity\n",
    "            if wdDataInformation[\"type\"] == \"externalString\":\n",
    "                realValue = getEntityTitle(wdGetEntity(currentInformation[\"id\"]))\n",
    "            \n",
    "            # The data is an array of names of an array of external entities\n",
    "            elif wdDataInformation[\"type\"] == \"externalArrayString\":\n",
    "                for currentEntityInformation in currentInformation:\n",
    "                    entityToAppend = getEntityTitle(wdGetEntity(currentEntityInformation[\"id\"]))\n",
    "                    \n",
    "                    if realValue is None and not entityToAppend is None:\n",
    "                        realValue = []\n",
    "\n",
    "                    if not entityToAppend is None:\n",
    "                        realValue.append(entityToAppend)\n",
    "            \n",
    "            # The data is a property of an external WikiData entity\n",
    "            elif wdDataInformation[\"type\"] == \"externalProperty\":\n",
    "                realValue = getDataValue(wdGetProperty(\n",
    "                    entityID=currentInformation[\"id\"],\n",
    "                    propertyID=wdDataInformation[\"targetProperty\"]\n",
    "                ))\n",
    "                \n",
    "            # The data is a property of the entity, positioned in the field \"targetProperty\"\n",
    "            elif wdDataInformation[\"type\"] == \"inValueArray\":\n",
    "                for currentEntityInformation in currentInformation:\n",
    "                    entityToAppend = currentEntityInformation[wdDataInformation[\"targetProperty\"]]\n",
    "\n",
    "                    if realValue is None and not entityToAppend is None:\n",
    "                        realValue = []\n",
    "\n",
    "                    if not entityToAppend is None:\n",
    "                        realValue.append(entityToAppend)\n",
    "\n",
    "            # The data is a property of the entity, positioned in the field \"targetProperty\"\n",
    "            elif wdDataInformation[\"type\"] == \"inValue\":\n",
    "                realValue = currentInformation[wdDataInformation[\"targetProperty\"]]\n",
    "\n",
    "            # The data is a datetime\n",
    "            elif wdDataInformation[\"type\"] == \"date\":\n",
    "                realValue = getDateFromInformation(\n",
    "                    currentInformation[\"time\"],\n",
    "                    currentInformation[\"precision\"]\n",
    "                )\n",
    "\n",
    "        # Set the final value\n",
    "        artistExtractedInformation[keyValue] = realValue\n",
    "    \n",
    "    return artistExtractedInformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same-formatted artist information retrieved by MusicBrainz\n",
    "def getArtistInformationMB(artistInformation):\n",
    "    artistExtractedInformation = {}\n",
    "\n",
    "    # MusicBrainz doesn't provide separated Name and Surnames\n",
    "    artistExtractedInformation[\"name\"] = None\n",
    "    artistExtractedInformation[\"surname\"] = None\n",
    "\n",
    "    # Search for the legal name in the aliases\n",
    "    try:\n",
    "        artistExtractedInformation[\"birthName\"] = None\n",
    "        \n",
    "        for artistAlias in artistInformation[\"aliases\"]:\n",
    "            if artistAlias[\"type\"] == \"Legal name\":\n",
    "                artistExtractedInformation[\"birthName\"] = artistAlias[\"name\"]\n",
    "                \n",
    "                # Often the sort name is in the form \"surname, name\"\n",
    "                nameAndSurname = artistAlias[\"sort-name\"].split(\",\")\n",
    "                artistExtractedInformation[\"surname\"] = [nameAndSurname[0].strip()]\n",
    "                artistExtractedInformation[\"name\"] = [nameAndSurname[1].strip()]\n",
    "    except:\n",
    "        artistExtractedInformation[\"birthName\"] = None\n",
    "\n",
    "    # If there is the life-span begin (birthDate for person, foundation for group), then set it as birthDate\n",
    "    try:\n",
    "        artistExtractedInformation[\"birthDate\"] = artistInformation[\"life-span\"][\"begin\"]\n",
    "    except:\n",
    "        artistExtractedInformation[\"birthDate\"] = None\n",
    "    \n",
    "    # If there is the life-span end (deathDate for person, disbandment for group), then set it as deathDate\n",
    "    try:\n",
    "        artistExtractedInformation[\"deathDate\"] = artistInformation[\"life-span\"][\"end\"]\n",
    "    except:\n",
    "        artistExtractedInformation[\"deathDate\"] = None\n",
    "    \n",
    "    # If there is the country iso code, then set it as country\n",
    "    try:\n",
    "        artistExtractedInformation[\"country\"] = artistInformation[\"country\"]\n",
    "    except:\n",
    "        artistExtractedInformation[\"country\"] = None\n",
    "    \n",
    "    artistExtractedInformation[\"gender\"] = None\n",
    "    artistExtractedInformation[\"recordLabels\"] = None\n",
    "    artistExtractedInformation[\"instruments\"] = None\n",
    "\n",
    "    return artistExtractedInformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People Object Generator \n",
    "We define a function to generate objects of type \"people\" to be inserted in the final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the object to insert in the DataFrame\n",
    "def generatePeopleObject(peopleInfo):\n",
    "    # Set the complete name, the name and the surname\n",
    "    completeName = peopleInfo[\"birthName\"] if not peopleInfo[\"birthName\"] is None else peopleInfo[\"entityName\"]\n",
    "\n",
    "    # Name and Surname are arrays of strings (if a person has more than one name or surname)\n",
    "    name = peopleInfo[\"name\"]\n",
    "    surname = peopleInfo[\"surname\"]\n",
    "\n",
    "    # If there is no name, but there is surname and complete name\n",
    "    # retrieve the name by substracting the surname from the complete name\n",
    "    if name is None and not surname is None and not completeName is None:\n",
    "        # Use as position to cut only the first surname\n",
    "        # This because I don't know how surnames are concatenated (by a -, or by space or other chars)\n",
    "        if completeName.find(surname[0]) >= 0:\n",
    "            surnamePosition = completeName.find(surname[0]) - 1\n",
    "            name = completeName[:surnamePosition].strip()\n",
    "\n",
    "        # Set the final surname joining the arrays\n",
    "        surname = \" \".join(surname)\n",
    "\n",
    "    # If there is no surname, but there is name and complete name\n",
    "    # retrieve the surname by substracting the name from the complete name\n",
    "    elif not name is None and surname is None and not completeName is None:\n",
    "        # Use as position to cut only the last name\n",
    "        # This because I don't know how names are concatenated (by a -, or by space or other chars)\n",
    "        if completeName.find(name[-1]) >= 0:\n",
    "            namePosition = completeName.find(name[-1]) + len(name[-1])\n",
    "            surname = completeName[namePosition:].strip()\n",
    "\n",
    "        # Set the final name joining the arrays\n",
    "        name = \" \".join(name)\n",
    "\n",
    "    # If there is no name, no surname but there is complete name\n",
    "    # retrieve the name and the surname by dividing at the first space\n",
    "    # If there are no space, set as name the complete name, and null for the surname\n",
    "    elif name is None and surname is None and not completeName is None:\n",
    "        namePosition = completeName.find(\" \")\n",
    "        surnamePosition = completeName.find(\" \")\n",
    "        \n",
    "        if namePosition >= 0:\n",
    "            name = completeName[:surnamePosition].strip()\n",
    "            surname = completeName[namePosition:].strip()\n",
    "        else:\n",
    "            name = completeName\n",
    "    \n",
    "    # If there are both name and surname, set the final name and surname joining the arrays\n",
    "    elif not name is None and not surname is None:\n",
    "        name = \" \".join(name)\n",
    "        surname = \" \".join(surname)\n",
    "    \n",
    "    # If the name or the surname is an empty string, consider it as null\n",
    "    name = name if not name is None and len(name) > 0 else None\n",
    "    surname = surname if not surname is None and len(surname) > 0 else None\n",
    "\n",
    "    # Get and setup the artist information needed\n",
    "    peopleObject = {\n",
    "        \"id\": peopleInfo[\"wdID\"] if not peopleInfo[\"wdID\"] is None else peopleInfo[\"mbID\"],\n",
    "        \"name\": name,\n",
    "        \"surname\": surname,\n",
    "        \"birthdate\": peopleInfo[\"birthDate\"] if peopleInfo[\"birthDate\"].index(\"?\") < 0 else None,\n",
    "        \"deathdate\": peopleInfo[\"deathDate\"] if peopleInfo[\"deathDate\"].index(\"?\") < 0 else None,\n",
    "        \"nationality\": peopleInfo[\"country\"],\n",
    "        \"artist\": peopleInfo[\"artistID\"],\n",
    "        \"complete_name\": peopleInfo[\"birthName\"],\n",
    "        \"entity_name\": peopleInfo[\"entityName\"],\n",
    "        \"gender\": peopleInfo[\"gender\"],\n",
    "        \"recordLabels\": \",\".join(peopleInfo[\"recordLabels\"]) if (not peopleInfo[\"recordLabels\"] is None) and len(peopleInfo[\"recordLabels\"]) > 0 else None,\n",
    "        \"instruments\": \",\".join(peopleInfo[\"instruments\"]) if (not peopleInfo[\"instruments\"] is None) and len(peopleInfo[\"instruments\"]) > 0 else None,\n",
    "    }\n",
    "\n",
    "    return peopleObject\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Utilities\n",
    "We define functions to choose the best result both from a ***WikiData*** Query or a ***MusicBrainz*** Query :\n",
    "\n",
    "* ***WikiData***: Each entity obtained with the query has a little description called \"snippet\". The snippets are then used to filter the entities using a list of banned keywords. Finally, the remaining entities are ordered according to the presence of some keywords (with different levels of importance), and the first result is taken.\n",
    "* ***MusicBrainz***: Take the first result matched by the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get the best result from the WikiData query\n",
    "def chooseBestQueryResult(queryResults):\n",
    "    # If there are no results, return null\n",
    "    if queryResults is None or not \"query\" in queryResults.keys():\n",
    "        return None\n",
    "    \n",
    "    # WikiData query results are in query --> search\n",
    "    queryResults = queryResults[\"query\"][\"search\"]\n",
    "\n",
    "    # If there are no query results, return null\n",
    "    if len(queryResults) <= 0:\n",
    "        return None\n",
    "    \n",
    "    print(\"\\n🔍 [SEARCH RESULTS]\")\n",
    "\n",
    "    # Get an array of possibile results\n",
    "    artistResults = []\n",
    "    for queryResult in queryResults:\n",
    "        # Snippet is a brief description of the entity\n",
    "        querySnippet = queryResult[\"snippet\"].lower()\n",
    "\n",
    "        # If there are one or more of the keywords, than probably the result is a valid one\n",
    "        # keywords are in order of importance, so for example if there are two results\n",
    "        # containing the first one the word \"artist\" and the second one the word \"rapper\"\n",
    "        # the second one will be chosen\n",
    "        keyWords = [\n",
    "                        \"dj\",\n",
    "                        \"singer\",\n",
    "                        \"songwriter\",\n",
    "                        \"rapper\",\n",
    "                        \"duo\",\n",
    "                        \"trio\",\n",
    "                        \"group\",\n",
    "                        \"band\",\n",
    "                        \"orchestra\",\n",
    "                        \"producer\",\n",
    "                        \"music\",\n",
    "                        \"artist\"\n",
    "                ]\n",
    "        \n",
    "        # If there are one or more of the banned keyword, the result is not considered\n",
    "        bannedKeyWords = [\n",
    "                            \"album\",\n",
    "                            \"discography\",\n",
    "                            \"single\",\n",
    "                            \"song \",\n",
    "                            \"wikimedia\",\n",
    "                            \"film\"\n",
    "                        ]\n",
    "\n",
    "        # Create an array with the positions of where each keyword has been found (-1 if not found)\n",
    "        # Both for keywords and banned keywords\n",
    "        keyFindResults = np.array([querySnippet.find(keyWord)\n",
    "                                    for keyWord in keyWords])\n",
    "        bannedKeyFindResults = np.array([querySnippet.find(keyWord)\n",
    "                                            for keyWord in bannedKeyWords])\n",
    "\n",
    "        # Get the keywords found (their position in the array of keywords)\n",
    "        matchedKeys = np.where(keyFindResults >= 0)[0]\n",
    "        bannedMatchedKeys = np.where(bannedKeyFindResults >= 0)[0]\n",
    "\n",
    "        # Check if there is a match\n",
    "        hasMatch = False\n",
    "\n",
    "        # If there are no banned words and there is at least one keyword, than there is a match\n",
    "        if len(bannedMatchedKeys) <= 0 and len(matchedKeys) > 0:\n",
    "            hasMatch = True\n",
    "            artistResults.append(matchedKeys)\n",
    "        \n",
    "        # Otherwise there is no match\n",
    "        else:\n",
    "            artistResults.append([])\n",
    "\n",
    "        # Print the query (with --> if probably a valid match)\n",
    "        hasMatchStr = \"--> \" if hasMatch else \"- \"\n",
    "        print(hasMatchStr + querySnippet)\n",
    "\n",
    "    # For each query, get the index of the more important matched word, or infinity if no matched words\n",
    "    # Other algorithms probably can be used, for example considering also the number of matches\n",
    "    artistResults = [k[0] if len(k) > 0 else np.inf for k in artistResults]\n",
    "\n",
    "    # If there are no matches, return null\n",
    "    if np.min(artistResults) == np.inf:\n",
    "        return None\n",
    "\n",
    "    # Then select the result with the minimum value\n",
    "    artistResult = queryResults[np.argmin(artistResults)]\n",
    "        \n",
    "    return artistResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get the best result from MusicBrainz query\n",
    "def chooseBestQueryResultMB(queryResults, expectedArtist=None):\n",
    "    # If there are no results, return null\n",
    "    if queryResults is None or not \"artists\" in queryResults.keys():\n",
    "        return None\n",
    "    \n",
    "    # MusicBrainz (artists) query results are in query --> artists\n",
    "    queryResults = queryResults[\"artists\"]\n",
    "    \n",
    "    # If there are no query results, return null\n",
    "    if len(queryResults) <= 0:\n",
    "        return None\n",
    "\n",
    "    # By default, get the first result\n",
    "    artistResult = queryResults[0]\n",
    "\n",
    "    # If the name of the artist is passed, try to get a best match\n",
    "    if not expectedArtist is None:\n",
    "        for result in queryResults:\n",
    "            # If the expected artist name is contained in the result name, than there is a match\n",
    "            if expectedArtist.lower() in result[\"name\"].lower():\n",
    "                artistResult = result\n",
    "                break\n",
    "    \n",
    "    # Get the artist information from MusicBrainz\n",
    "    artistResult = mbGetArtist(artistResult[\"id\"])\n",
    "\n",
    "    # Set also the \"title\" and the \"snippet\", to get a object equal to the WikiData one\n",
    "    if not artistResult is None:\n",
    "        # Set as title the WikiData entity ID of the artist\n",
    "        artistResult[\"title\"] = getMBWikiDataEntityID(artistResult)\n",
    "        # And as snippet the name of the artist\n",
    "        artistResult[\"snippet\"] = artistResult[\"name\"]\n",
    "\n",
    "    return artistResult\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval\n",
    "\n",
    "### Data Retrieval from WikiData and MusicBrainz\n",
    "We define two functions to retrieve data for a specific artist both from ***Wikidata API*** and ***MusicBrainz API***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWikiDataInformation(artistResult, artistID, artistName):\n",
    "    # Get the entityID. WikiData returns it in the title field\n",
    "    entityID = artistResult[\"title\"]\n",
    "    \n",
    "    # Get the WikiData entity data\n",
    "    entityObject = wdGetEntity(entityID)\n",
    "\n",
    "    # Get the WikiData claims of the entity. Claims is the list of properties\n",
    "    entityClaims = None\n",
    "    # The entity name is temporary the title\n",
    "    entityName = artistResult[\"title\"]\n",
    "\n",
    "    # If there are properties, set the entity claims\n",
    "    # And set the name as the entity title (the title of the WikiData page)\n",
    "    if \"claims\" in entityObject.keys():\n",
    "        entityClaims = entityObject[\"claims\"]\n",
    "        entityName = getEntityTitle(entityObject)\n",
    "    \n",
    "    # List all the members of the artist (if one the artist is a person, otherwise this will a list of persons)\n",
    "    artistMembers = []\n",
    "\n",
    "    # Data found or not\n",
    "    hasFoundData = True\n",
    "    isSingleArtist = False\n",
    "    \n",
    "    if not entityClaims is None:\n",
    "        # If the WikiData entity has the property \"instanceOf\" to \"human\", then the artist is a single person artist\n",
    "        if WD_MAP[\"instanceOf\"] in entityClaims.keys() and getDataValue(entityClaims, WD_MAP[\"instanceOf\"])[\"id\"] == WD_MAP[\"human\"]:\n",
    "            isSingleArtist = True\n",
    "            # Get the information from WikiData\n",
    "            artistInformation = getEntityInformation(entityClaims)\n",
    "            # And set other additional information like the artist name, the entity title and the WikiData ID\n",
    "            artistInformation[\"artistID\"] = artistID\n",
    "            artistInformation[\"artistName\"] = artistName\n",
    "            artistInformation[\"entityName\"] = entityName\n",
    "            artistInformation[\"mbID\"] = mbArtistResult[\"id\"] if not mbArtistResult is None else None\n",
    "            artistInformation[\"wdID\"] = entityID\n",
    "\n",
    "            # And add it to the array of artists\n",
    "            artistMembers.append(artistInformation)\n",
    "        \n",
    "        # Otherwise, if the WikiData entity has the property \"hasPart\", then I can get the list of group members\n",
    "        elif WD_MAP[\"hasPart\"] in entityClaims.keys():\n",
    "            # Get only the \"hasPart\" property\n",
    "            groupInformation = getSubsetOfKeys(entityClaims, GROUP_KEYS)\n",
    "            # And get the ids of the WikiData pages as an array\n",
    "            groupMembers = getDataValue(groupInformation, \"hasPart\", expectArray=True)\n",
    "\n",
    "            # Get the record labels\n",
    "            recordLabelsInformation = getDataValue(groupInformation, \"recordLabels\", expectArray=True)\n",
    "            recordLabels = None\n",
    "            if not recordLabelsInformation is None:\n",
    "                if recordLabels is None:\n",
    "                    recordLabels = []\n",
    "                for recordLabel in recordLabelsInformation:\n",
    "                    recordLabels.append(recordLabel[\"id\"])\n",
    "\n",
    "            # For each member, get the data\n",
    "            for groupMember in groupMembers:\n",
    "                # Get the WikiData entity\n",
    "                memberEntity = wdGetEntity(groupMember[\"id\"])\n",
    "\n",
    "                # If there is a valid WikiData page\n",
    "                if not memberEntity is None and \"claims\" in memberEntity.keys():\n",
    "                    # Get the properties and the title of the page\n",
    "                    memberEntityClaims = memberEntity[\"claims\"]\n",
    "                    memberEntityName = getEntityTitle(memberEntity)\n",
    "                    \n",
    "                    # And set the information of the artist\n",
    "                    artistInformation = getEntityInformation(memberEntityClaims)\n",
    "                    artistInformation[\"artistID\"] = artistID\n",
    "                    artistInformation[\"artistName\"] = artistName\n",
    "                    artistInformation[\"entityName\"] = memberEntityName\n",
    "                    artistInformation[\"mbID\"] = mbArtistResult[\"id\"] if not mbArtistResult is None else None\n",
    "                    artistInformation[\"wdID\"] = groupMember[\"id\"]\n",
    "                    artistInformation[\"recordLabels\"] = recordLabels\n",
    "\n",
    "                    # And add it to the array of artists\n",
    "                    artistMembers.append(artistInformation)\n",
    "        \n",
    "        # Otherwise probably the WikiData entity is neither a human neither a group, so try to use MusicBrainz data\n",
    "        else:\n",
    "            hasFoundData = False\n",
    "\n",
    "    # Otherwise try to use MusicBrainz data\n",
    "    else:\n",
    "        hasFoundData = False\n",
    "        \n",
    "    return artistMembers, hasFoundData, isSingleArtist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMusicBrainzInformation(mbArtistResult, artistID, artistName):    \n",
    "    artistMembers = []\n",
    "\n",
    "    hasFoundData = True\n",
    "    isSingleArtist = False\n",
    "\n",
    "    if not mbArtistResult is None:\n",
    "        # If the artist is a person get the information\n",
    "        if mbArtistResult[\"type\"] == \"Person\":\n",
    "            isSingleArtist = True\n",
    "\n",
    "            mbArtistInformation = getArtistInformationMB(mbArtistResult)\n",
    "            mbArtistInformation[\"entityName\"] = mbArtistResult[\"name\"]\n",
    "            mbArtistInformation[\"artistName\"] = artistName\n",
    "            mbArtistInformation[\"artistID\"] = artistID\n",
    "            mbArtistInformation[\"mbID\"] = mbArtistResult[\"id\"]\n",
    "            mbArtistInformation[\"wdID\"] = None\n",
    "\n",
    "            artistMembers.append(mbArtistInformation)\n",
    "\n",
    "            # If the artist is a group get the information\n",
    "        elif mbArtistResult[\"type\"] == \"Group\":\n",
    "            # Get the members of the group. Since in the mbArtistResult artist relationships are not retrieved,\n",
    "            # with downloadMember=True I force to get the artist information from the web\n",
    "            mbGroupMembers = getMBGroupMembers(\n",
    "                mbArtistResult, downloadMembers=True)\n",
    "            \n",
    "            # Add the group members\n",
    "            if not mbGroupMembers is None:\n",
    "                for mbGroupMember in mbGroupMembers:\n",
    "                    if not mbGroupMember is None:\n",
    "                        # A member of a group can have a WikiData page\n",
    "                        mbMemberWikiDataEntityID = getMBWikiDataEntityID(mbGroupMember)\n",
    "\n",
    "                        hasFoundWikiData = False\n",
    "                        mbMemberInformation = None\n",
    "                        \n",
    "                        # If yes, try to get the data from WikiData\n",
    "                        if not mbMemberWikiDataEntityID is None:\n",
    "                            mbGroupMember[\"title\"] = mbMemberWikiDataEntityID\n",
    "                            mbMemberInformation, hasFoundWikiData, _ = getWikiDataInformation(\n",
    "                                artistResult=mbGroupMember, artistID=artistID, artistName=artistName)\n",
    "                            \n",
    "                            if not mbMemberInformation is None and len(mbMemberInformation) > 0:\n",
    "                                # Since it is only one person, and getWikiDataInformation return an array of\n",
    "                                # people, take only the first one, if there is\n",
    "                                mbMemberInformation = mbMemberInformation[0]\n",
    "\n",
    "                        # Otherwise use the data from MusicBrainz\n",
    "                        if not hasFoundWikiData:\n",
    "                            mbMemberInformation = getArtistInformationMB(mbGroupMember)\n",
    "                            mbMemberInformation[\"entityName\"] = mbGroupMember[\"name\"]\n",
    "                            mbMemberInformation[\"artistName\"] = artistName\n",
    "                            mbMemberInformation[\"artistID\"] = artistID\n",
    "                            mbMemberInformation[\"mbID\"] = mbGroupMember[\"id\"]\n",
    "                            mbMemberInformation[\"wdID\"] = None\n",
    "\n",
    "                        artistMembers.append(mbMemberInformation)\n",
    "\n",
    "        else:\n",
    "            hasFoundData = False\n",
    "    else:\n",
    "        hasFoundData = False\n",
    "\n",
    "    return artistMembers, hasFoundData, isSingleArtist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "We load the CSV file with the data about the artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "artists = pd.read_csv(artistsPath, sep=\",\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peopleDF = None\n",
    "peopleCols = [\"id\", \"name\", \"surname\", \"birthdate\", \"deathdate\",\n",
    "              \"nationality\", \"artist\", \"complete_name\", \"entity_name\", \"gender\", \"recordLabels\", \"instruments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup DataFrames\n",
    "peopleDF = pd.DataFrame([], columns=peopleCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Creation\n",
    "\n",
    "We retrieve personal data about artists according to the following workflow:\n",
    "1. We search for the artist on *MusicBrainz*\n",
    "2. We take the first result (according to lexicografically matching) and check if a *WikiData* link is present (almost everytime)\n",
    "3. Using the *WikiData* link, I retrieve the artist:\n",
    "    * If the artist is tagged as *human*, we take all the personal information.\n",
    "    * If the artist has the property *hasPart*, it means that we have a group. We then retrieve the personal information of all the members.\n",
    "4. If the *WikiData* link is not present, we perform a query on *WikiData* and we perform the same actions of point 3.\n",
    "5. If the *WikiData* link is not present and the query of point 4 was unsucessfull or incomplete, we search for data on *MusicBrainz*. If present, we take the personal information directly from *MusicBrainz*:\n",
    "    * If the artist is a single person, we simply take the data.\n",
    "    * If the artist is a group, we search on *WikiData* for each members. If nothing is found, we use data directly from *MusicBrainz*\n",
    "6. Finally, we remove duplicates and we obtain a dataframe with ***Name, Surname, BirthDate, DeathDate, Nationality, ArtistName (according to the original CSV)***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the album DataFrame\n",
    "index = 0\n",
    "\n",
    "#for artistID, row in zip([\"7DMveApC7UnC2NPfPvlHSU\"], [{\"name\": \"Cheat Codes\"}]):\n",
    "#for artistID, row in zip([\"0vR2qb8m9WHeZ5ByCbimq2\"], [{\"name\": \"Reik\"}]):\n",
    "#for artistID, row in zip([\"2T1aUibqR2QC2sINIDQOAK\"], [{\"name\": \"Mambo Kingz\"}]):\n",
    "#for artistID, row in zip([\"6YBgd2LKccEB3pX6UaW1Yp\", \"47z0zz9ZMCn9GBiPRTn5Bc\"], [{\"name\": \"Thegiornalisti\"}, {\"name\": \"Tommaso Paradiso\"}]):\n",
    "\n",
    "for artistID, row in artists.iterrows():\n",
    "    artistName = str(row[\"name\"])\n",
    "\n",
    "    print(\"\\n\\n\\n🧑‍🎤 [[\" + artistName.upper() + \"]]\")\n",
    "\n",
    "    # Search the artist from MusicBrainz\n",
    "    mbQueryResults = mbQuery(artistName)\n",
    "    mbArtistResult = chooseBestQueryResultMB(mbQueryResults, artistName)\n",
    "    artistResult = mbArtistResult.copy() if not mbArtistResult is None else None\n",
    "\n",
    "    # If on MusicBrainz there isn't the wanted artist or it doesn't have WikiData page\n",
    "    # Try to search directly on WikiData\n",
    "    if artistResult is None or artistResult[\"title\"] is None:\n",
    "        print(\"\\n🛑 [NO MATCHES ON MUSICBRAINZ, TRYING TO WIKIDATA]\")\n",
    "        wdQueryResults = wdQuery(artistName)\n",
    "        artistResult = chooseBestQueryResult(wdQueryResults)\n",
    "    \n",
    "    # If there are is no match also on WikiData, then skip the artist\n",
    "    if artistResult is None:\n",
    "        print(\"\\n🛑 [NO MATCHES ON WIKIDATA]\")\n",
    "        continue\n",
    "    \n",
    "    # Log the final choose\n",
    "    print(\"\\n✔️ [FINAL CHOOSE] \" + artistResult[\"title\"] +\n",
    "            \" - \" + artistResult[\"snippet\"])\n",
    "\n",
    "    # Try to get the data about artists from WikiData\n",
    "    artistMembers, hasFoundData, isSingleArtist = getWikiDataInformation(\n",
    "        artistResult=artistResult, artistID=artistID, artistName=artistName)\n",
    "\n",
    "    # If no data on WikiData, try to get the information from MusicBrainz\n",
    "    if not hasFoundData:\n",
    "        print(\"\\n🛑 [NO INFORMATION TO RETRIEVE, TRYING WITH MUSICBRAINZ DATA]\")\n",
    "\n",
    "        artistMembers, hasFoundData, isSingleArtist = getMusicBrainzInformation(\n",
    "            mbArtistResult=mbArtistResult, artistID=artistID, artistName=artistName)\n",
    "        \n",
    "        if not hasFoundData:\n",
    "            print(\"🛑 [NO MUSICBRAINZ DATA]\")\n",
    "    \n",
    "    # If data found, check if it is a single artist or a band\n",
    "    if hasFoundData:\n",
    "        if isSingleArtist:\n",
    "            print(\"\\n👨 [SINGLE ARTIST]\")\n",
    "        else:\n",
    "            print(\"\\n👪 [MEMBERS OF GROUP]\")\n",
    "    \n",
    "    # Create a list of people objects to insert in the DataFrame\n",
    "    peopleObjList = []\n",
    "    print(\"\\n🗃️ [PEOPLE RETRIEVED]\")\n",
    "    for peopleInfo in artistMembers:\n",
    "        peopleObject = generatePeopleObject(peopleInfo)\n",
    "        \n",
    "        print(peopleObject[\"entity_name\"] + \": \" + json.dumps(peopleObject))\n",
    "        \n",
    "        peopleObjList.append(list(peopleObject.values()))\n",
    "\n",
    "    # Create rows DataFrame for the people\n",
    "    peopleObjDF = pd.DataFrame(peopleObjList, columns=peopleCols)\n",
    "\n",
    "    # Add the people info to the DataFrame\n",
    "    peopleDF = pd.concat([peopleDF, peopleObjDF], ignore_index=True)\n",
    "\n",
    "    # Remove duplicates (a person can be in two different artists/groups, so it is necessary to keep both)\n",
    "    # The aggregation of same person to get all the artists in which compare is made grouping DataFrame rows by id\n",
    "    peopleDF.drop_duplicates(subset=[\"id\", \"artist\"], ignore_index=True)\n",
    "\n",
    "    # Print stats every 5000 people\n",
    "    '''\n",
    "    if index % 5000 == 0:\n",
    "        print(\"\\n\\n🎧 [STATUS INFO #{row}]\".format(row=index))\n",
    "        print(peopleDF.info())\n",
    "    '''\n",
    "    \n",
    "    # Save DataFrame to file every 100 people\n",
    "    if index % 100 == 0:\n",
    "        print(\"\\n\\n💾 [STATUS INFO #{row}] Dataset saved\\n\".format(row=index))\n",
    "\n",
    "        peopleDF.to_csv(peoplePath)\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "# Print info about the DataFrames\n",
    "print(peopleDF.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates (a person can be in two different artists/groups, so it is necessary to keep both)\n",
    "# The aggregation of same person to get all the artists in which compare is made grouping DataFrame rows by id\n",
    "peopleDF = peopleDF.drop_duplicates(subset=[\"id\", \"artist\"], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets to file\n",
    "peopleDF.to_csv(peoplePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "peopleDF = pd.read_csv(peoplePath, sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumentsDF = None\n",
    "instrumentsCols = [\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup DataFrames\n",
    "instrumentsDF = pd.DataFrame([])\n",
    "\n",
    "instruments = []\n",
    "# Iterate over people DataFrame\n",
    "for index, row in peopleDF.iterrows():\n",
    "    if not row[\"instruments\"] is None:\n",
    "        for instrument in row[\"instruments\"].split(\",\"):\n",
    "            instruments.append(instrument)\n",
    "\n",
    "instrumentsDF = pd.DataFrame(instruments, columns=instrumentsCols)\n",
    "instrumentsDF = instrumentsDF.dropna(ignore_index=True)\n",
    "instrumentsDF = instrumentsDF.drop_duplicates(ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(instrumentsDF.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets to file\n",
    "instrumentsDF.to_csv(instrumentsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Record Labels information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "peopleDF = pd.read_csv(peoplePath, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordLabelsDF = None\n",
    "recordLabelsCols = [\"id\", \"name\", \"country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup DataFrames\n",
    "recordLabelsIDsDF = pd.DataFrame([])\n",
    "\n",
    "recordLabelsIDs = []\n",
    "# Iterate over people DataFrame\n",
    "for index, row in peopleDF.iterrows():\n",
    "    if not row[\"recordLabels\"] is None:\n",
    "        for rLabel in row[\"recordLabels\"].split(\",\"):\n",
    "            recordLabelsIDs.append(rLabel)\n",
    "\n",
    "recordLabelsIDsDF = pd.DataFrame(recordLabelsIDs, columns=[\"id\"])\n",
    "recordLabelsIDsDF = recordLabelsIDsDF.dropna(ignore_index=True)\n",
    "recordLabelsIDsDF = recordLabelsIDsDF.drop_duplicates(ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recordLabelsIDsDF.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordLabelsData = []\n",
    "# Iterate over people DataFrame\n",
    "for index, row in recordLabelsIDsDF.iterrows():\n",
    "    # Get the WikiData entity data\n",
    "    entityObject = wdGetEntity(row[\"id\"])\n",
    "\n",
    "    # Get the WikiData claims of the entity. Claims is the list of properties\n",
    "    entityClaims = None\n",
    "    # The entity name is temporary the title\n",
    "    entityName = None\n",
    "\n",
    "    # If there are properties, set the entity claims\n",
    "    # And set the name as the entity title (the title of the WikiData page)\n",
    "    if \"claims\" in entityObject.keys():\n",
    "        entityClaims = entityObject[\"claims\"]\n",
    "        entityName = getEntityTitle(entityObject)\n",
    "\n",
    "    if not entityClaims is None:\n",
    "        labelInformation = getEntityInformation(\n",
    "            entityClaims, keysToGet=RECORDLABEL_KEYS)\n",
    "        \n",
    "        recordLabelsData.append([row[\"id\"], entityName, labelInformation[\"country2\"]])\n",
    "\n",
    "recordLabelsDF = pd.DataFrame(recordLabelsData, columns=recordLabelsCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recordLabelsDF.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets to file\n",
    "recordLabelsDF.to_csv(recordLabelsPath)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
